import cv2
from deepface import DeepFace
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from collections import deque, Counter
import random
import datetime
import threading
import os
from flask import Flask, render_template, Response, jsonify, send_from_directory

app = Flask(__name__)

# --- è¨­å®šå€ ---
STABILITY_WINDOW = 7  # ç©©å®šåº¦è¦–çª—å¤§å° (è¶Šå¤§è¶Šç©©ä½†è¶Šæ…¢)
FRAME_WIDTH = 640
FRAME_HEIGHT = 480

# è¨­å®šå­—å‹è·¯å¾‘ (Windows é è¨­)
font_path_tw = "C:/Windows/Fonts/msjh.ttc"       # å¾®è»Ÿæ­£é»‘é«”
font_path_emoji = "C:/Windows/Fonts/seguiemj.ttf" # Windows Emoji å­—å‹

# å˜—è©¦è¼‰å…¥å­—å‹ï¼Œè‹¥å¤±æ•—å‰‡ä½¿ç”¨é è¨­ (é¿å…ç¨‹å¼å´©æ½°)
try:
    font_tw = ImageFont.truetype(font_path_tw, 30)
    font_emoji = ImageFont.truetype(font_path_emoji, 60)
except IOError:
    print("âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°æŒ‡å®šå­—å‹ï¼Œå°‡ä½¿ç”¨ç³»çµ±é è¨­å­—å‹ (ä¸­æ–‡/Emoji å¯èƒ½ç„¡æ³•æ­£å¸¸é¡¯ç¤º)")
    font_tw = ImageFont.load_default()
    font_emoji = ImageFont.load_default()

# --- æˆªåœ–ç›¸é—œè¨­å®š ---
SNAPSHOT_FOLDER = 'snapshots'
if not os.path.exists(SNAPSHOT_FOLDER):
    os.makedirs(SNAPSHOT_FOLDER)

# --- å…¨åŸŸè®Šæ•¸ ---
global_frame = None       # ç”¨ä¾†æš«å­˜æœ€æ–°ç•«é¢ä¾›æˆªåœ–ç”¨
lock = threading.Lock()   # åŸ·è¡Œç·’é–ï¼Œç¢ºä¿è®€å¯«å®‰å…¨

# --- é¡åˆ¥å®šç¾©ï¼šé£„æµ® Emoji ---
class FloatingEmoji:
    def __init__(self, emoji_char, start_x, start_y):
        self.char = emoji_char
        self.x = start_x
        self.y = start_y
        self.speed = random.uniform(3, 7)    # ä¸Šå‡é€Ÿåº¦
        self.drift = random.uniform(-1, 1)   # å·¦å³é£„ç§»
        
    def update(self):
        self.y -= self.speed
        self.x += self.drift
        
    def is_off_screen(self):
        return self.y < -50 # è¶…å‡ºä¸Šæ–¹é‚Šç•Œ

    def draw(self, draw_obj):
        draw_obj.text((self.x, self.y), self.char, font=font_emoji, fill=(255, 255, 255))

# --- åˆå§‹åŒ–æ¨¡å‹èˆ‡è®Šæ•¸ ---
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
particles = []
emotion_queue = deque(maxlen=STABILITY_WINDOW)
spawn_timer = 0

# æƒ…ç·’è…³æœ¬è¨­å®š
emotion_script = {
    'sad':      {'msg': "ä»Šå¤©æ€éº¼äº†ï¼Ÿå‘¼å‘¼", 'emoji': "ğŸ˜¢", 'color': (100, 149, 237)},
    'happy':    {'msg': "çœ‹èµ·ä¾†å¿ƒæƒ…å¾ˆå¥½å–”ï¼", 'emoji': "ğŸ˜„", 'color': (255, 105, 180)},
    'angry':    {'msg': "æ·±å‘¼å¸... åˆ¥ç”Ÿæ°£",   'emoji': "ğŸ˜¤", 'color': (255, 69, 0)},
    'neutral':  {'msg': "ä¿æŒå¹³éœ...",          'emoji': None, 'color': (200, 200, 200)},
    'surprise': {'msg': "å“‡ï¼åš‡åˆ°äº†å—ï¼Ÿ",      'emoji': "ğŸ˜²", 'color': (255, 215, 0)},
    'fear':     {'msg': "åˆ¥æ€•ï¼Œæˆ‘åœ¨é€™",        'emoji': "ğŸ˜±", 'color': (148, 0, 211)},
    'disgust':  {'msg': "ä¸å–œæ­¡å—ï¼Ÿ",          'emoji': "ğŸ¤¢", 'color': (50, 205, 50)}
}

def get_most_frequent_emotion(queue):
    if not queue: return None
    return Counter(queue).most_common(1)[0][0]

# --- æ ¸å¿ƒé‚è¼¯ï¼šå½±åƒç”¢ç”Ÿå™¨ ---
def generate_frames():
    global particles, spawn_timer, global_frame, emotion_queue
    
    cap = cv2.VideoCapture(0)
    # å¼·åˆ¶è¨­å®šè§£æåº¦ï¼Œç¢ºä¿æ•ˆèƒ½èˆ‡ç¹ªåœ–ä½ç½®æ­£ç¢º
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)

    while True:
        success, frame = cap.read()
        if not success:
            break
        
        # 1. é¡åƒç¿»è½‰ (è®“æ“ä½œæ›´ç›´è¦º)
        frame = cv2.flip(frame, 1)

        # 2. äººè‡‰åµæ¸¬ (é‡å°ä¹¾æ·¨çš„åŸå§‹ç•«é¢)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.1, 5, minSize=(30, 30))

        if len(faces) == 0:
            emotion_queue.clear()

        detected_emotion_for_spawn = None
        face_draw_info = [] # æš«å­˜è¦ç•«çš„è³‡è¨Šï¼Œç¨å¾Œçµ±ä¸€ç•«

        for (x, y, w, h) in faces:
            face_roi = frame[y:y+h, x:x+w]
            try:
                # DeepFace åˆ†æ
                result = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)
                
                # åŠ å…¥ç©©å®šä½‡åˆ—
                emotion_queue.append(result[0]['dominant_emotion'])
                current_stable_emotion = get_most_frequent_emotion(emotion_queue)
                
                detected_emotion_for_spawn = current_stable_emotion

                # æº–å‚™ç¹ªåœ–è³‡è¨Š
                if current_stable_emotion in emotion_script:
                    script = emotion_script[current_stable_emotion]
                    face_draw_info.append({
                        'rect': (x, y, w, h),
                        'msg': script['msg'],
                        'color': script['color']
                    })
            except Exception:
                pass

        # 3. PIL ç¹ªåœ–è™•ç† (é–‹å§‹åœ¨ç•«é¢ä¸ŠåŠ æ–™)
        img_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)

        # A. è™•ç† Emoji ç²’å­ç”¢ç”Ÿ
        if detected_emotion_for_spawn and emotion_script[detected_emotion_for_spawn]['emoji']:
            target_emoji = emotion_script[detected_emotion_for_spawn]['emoji']
            spawn_timer += 1
            if spawn_timer > 5: # æ§åˆ¶ç”¢ç”Ÿé »ç‡
                start_x = random.randint(50, FRAME_WIDTH - 50)
                start_y = FRAME_HEIGHT + 10
                particles.append(FloatingEmoji(target_emoji, start_x, start_y))
                spawn_timer = 0

        # B. æ›´æ–°ä¸¦ç¹ªè£½æ‰€æœ‰ç²’å­
        for p in particles:
            p.update()
            p.draw(draw)
        # æ¸…é™¤è¶…å‡ºç•«é¢çš„ç²’å­
        particles = [p for p in particles if not p.is_off_screen()]

        # C. ç¹ªè£½äººè‡‰æ¡†èˆ‡æ–‡å­—
        for info in face_draw_info:
            x, y, w, h = info['rect']
            color = info['color']
            # ç•«æ¡† (PIL åº§æ¨™: å·¦ä¸Šx, å·¦ä¸Šy, å³ä¸‹x, å³ä¸‹y)
            draw.rectangle([x, y, x+w, y+h], outline=color, width=3)
            # ç•«å­—
            draw.text((x, y - 40), info['msg'], font=font_tw, fill=color)

        # 4. è½‰å› OpenCV æ ¼å¼
        final_frame = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

        # 5. æ›´æ–°å…¨åŸŸè®Šæ•¸ (ä¾›æˆªåœ–ç”¨ï¼Œéœ€ä¸Šé–)
        with lock:
            global_frame = final_frame.copy()

        # 6. ç·¨ç¢¼æˆ JPEG ä¸²æµå‚³çµ¦ç¶²é 
        ret, buffer = cv2.imencode('.jpg', final_frame)
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

# --- Flask è·¯ç”±è¨­å®š ---

@app.route('/')
def index():
    """é¡¯ç¤ºä¸»ç¶²é """
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    """æä¾›å½±åƒä¸²æµ"""
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/snapshot')
def snapshot():
    """è™•ç†æˆªåœ–è«‹æ±‚"""
    global global_frame
    if global_frame is not None:
        # ç”¢ç”Ÿæª”å
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"snapshot_{timestamp}.jpg"
        filepath = os.path.join(SNAPSHOT_FOLDER, filename)
        
        # å­˜æª” (ä½¿ç”¨é–ç¢ºä¿å®‰å…¨)
        with lock:
            cv2.imwrite(filepath, global_frame)
            
        print(f"âœ… å·²æˆªåœ–ä¸¦å„²å­˜: {filepath}")
        return jsonify({"status": "success", "filename": filename})
    else:
        return jsonify({"status": "error", "message": "No frame available"})

@app.route('/snapshots/<filename>')
def get_snapshot_file(filename):
    """è®“å‰ç«¯å¯ä»¥è®€å–æˆªåœ–æª”æ¡ˆ"""
    return send_from_directory(SNAPSHOT_FOLDER, filename)

if __name__ == "__main__":
    # host='0.0.0.0' è®“å€åŸŸç¶²è·¯å…§çš„å…¶ä»–è£ç½®ä¹Ÿèƒ½é€£ç·š
    app.run(debug=True, host='0.0.0.0', port=5000)